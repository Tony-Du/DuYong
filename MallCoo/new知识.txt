
scp -P 33890  /mnt/apps/spark/conf/spark-env.sh thadoop002:/mnt/apps/spark/conf/
集群间不同节点之间的copy


jps -l|grep spark



salt '*' cmd.run "`which jps`|grep spark"


salt '*' cmd.run "ls /mnt/apps"


ps -ef |grep macloc
查看运行的进程


set mapreduce.job.queuename=long;
yarn中分配了最多20%的集群资源给long
单独的进程


impala 地址：
'hdfs://impala1:8020/user/hive/warehouse/medusa.db/event2/projectid=92/month=2017-11-01/event_type=25001/'



linux 后台运行 
1.& 命令
2.nohup 命令  




20171222需要补充的知识点
1. java 

集合；面向对象思想；读、写文件

2. python

pandas;处理和SQL的逻辑

3. 微信公众号，从微信拿数据

4. shell脚本



















