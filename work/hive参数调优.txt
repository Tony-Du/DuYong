

set hive.exec.dynamic.partition.mode=nonstrict;	 --无限制模式, 如果模式是strict，则必须有一个静态分区，且放在最前面 
set hive.exec.dynamic.partition=true;	         --启用自动分区

set hive.groupby.skewindata=true;			     --group by分组时出现数据倾斜(skew: 倾斜)

set hive.optimize.skewjoin=true;                 --如果是 join 过程出现倾斜应该设置为 true

set hive.merge.mapredfiles=true;				 --hive.merge.mapredfiles 这个指的是 在Map-Reduce的任务结束时合并小文件
set hive.merge.mapfiles = true                   --在Map-only的任务结束时合并小文件


set hive.optimize.sort.dynamic.partition=true;   --当该参数有效时，自动分区的字段将会在全局范围内被排序。
												 --这样，在reduce时，针对每一个分区，我们可以保证只有一个record writer，这样做的好处是在reduce时减轻内存压力

hive.optimize.sort.dynamic.partition
--Default Value: true in Hive 0.13.0 and 0.13.1; false in Hive 0.14.0 and later (HIVE-8151)
--Added In: Hive 0.13.0 with HIVE-6455
--When enabled, dynamic partitioning column will be globally sorted. This way we can keep only one record writer open for each partition value in the reducer thereby reducing the memory pressure on reducers.


set mapreduce.reduce.shuffle.input.buffer.percent	--设置copy阶段buffer占用的内存大小。The percentage of memory to be allocated from the maximum heap size to storing map outputs during the shuffle.

set mapreduce.reduce.shuffle.parallelcopies
默认值：5
说明：reuduce shuffle阶段并行传输数据的数量。这里改为10。集群大可以增大。


=======================================================================================================================


例：
set mapreduce.reduce.shuffle.input.buffer.percent=0.3;
set mapreduce.reduce.shuffle.parallelcopies=3;


sethive.exec.reducers.max=200;

setmapred.reduce.tasks= 200;---增大Reduce个数

sethive.groupby.mapaggr.checkinterval=100000;--这个是group的键对应的记录条数超过这个值则会进行分拆,值根据具体数据量设置

sethive.groupby.skewindata=true; --如果是group by过程出现倾斜 应该设置为true 

sethive.skewjoin.key=100000;--这个是join的键对应的记录条数超过这个值则会进行分拆,值根据具体数据量设置

sethive.optimize.skewjoin=true;--如果是join 过程出现倾斜应该设置为true