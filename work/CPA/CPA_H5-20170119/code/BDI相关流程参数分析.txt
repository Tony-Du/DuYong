
sudo su - hadoop -c "/opt/data-integration/kitchen.sh 
					-file=#system.BIGDATA_ETL_PATH#/app/cpa_h5_hourly/main.kjb 
					-param:SRC_FILE_DAY=#flow.src_file_day# 
					-param:SRC_FILE_HOUR=#flow.src_file_hour# 
					-level=Detailed"
=============================================================
cat /opt/data-integration/kitchen.sh

#!/bin/sh

BASEDIR="`dirname $0`"
cd "$BASEDIR"
DIR="`pwd`"
cd - > /dev/null

if [ "$1" = "-x" ]; then
  set LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$BASEDIR/lib
  export LD_LIBRARY_PATH
  export OPT="-Xruntracer $OPT"
  shift
fi

export IS_KITCHEN="true"

"$DIR/spoon.sh" -main org.pentaho.di.kitchen.Kitchen "$@"
==============================================================

#system.BIGDATA_ETL_PATH# -> BDI系统的参数-> /mnt/bigdata-bdi/bigdata/etl

#flow.src_file_day#  -> BDI某个流程的参数 -> src_file_day:substr(#flow.startDataTime#,0,8) 
#flow.src_file_hour# -> BDI某个流程的参数 -> src_file_hour:substr(#flow.startDataTime#,8,10)  
	-- 该处的substr(String,int,int)是BDI的函数
	-- flow.startDataTime -> 是设置调度时间里的“下次数据时间”

注：BDI中流程参数和计算都可以配置一些参数，
但是如果存在 hdfs_path、local_path 这样的参数，不能在计算中配置，需要在流程参数里面配置，否则会报错

===============================================================
hdfs_path /user/hive/warehouse/app.db/cpa_h5_hourly/src_file_day=#substr(#flow.startDataTime#,0,8)#/src_file_hour=#substr(#flow.startDataTime#,8,10)#
local_path /mnt/cpa/#substr(#flow.startDataTime#,0,8)#/hour
file_name cpa_h5_hour_#flow.startDataTime#.dat
src_file_day substr(#flow.startDataTime#,0,8)
src_file_hour substr(#flow.startDataTime#,8,10)


	/mnt/cpa/#flow.startDataTime#/day